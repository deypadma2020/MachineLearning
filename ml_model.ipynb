{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc502191",
   "metadata": {},
   "source": [
    "## MACHINE LEARNING MODELS: -\n",
    "\n",
    "#### üîπ Classical Models\n",
    "\n",
    "- Logistic Regression\n",
    "\n",
    "- K-Nearest Neighbors (KNN)\n",
    "\n",
    "- Support Vector Classifier (SVC)\n",
    "\n",
    "- Decision Tree\n",
    "\n",
    "- Naive Bayes\n",
    "\n",
    "#### üîπ Ensemble Models\n",
    "\n",
    "- Random Forest\n",
    "\n",
    "- Extra Trees\n",
    "\n",
    "- Bagging Classifier\n",
    "\n",
    "- AdaBoost\n",
    "\n",
    "- Gradient Boosting\n",
    "\n",
    "- XGBoost\n",
    "\n",
    "- LightGBM\n",
    "\n",
    "- CatBoost\n",
    "\n",
    "#### üîπ Meta-Ensemble Models\n",
    "\n",
    "- Voting Classifier\n",
    "\n",
    "- Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be55d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f0971ac",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e173f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    \"area\": [1400, 1600, 1700, 1875, 1100, 1550],\n",
    "    \"price\": [245000, 312000, 279000, 308000, 199000, 219000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "X = df[[\"area\"]]\n",
    "y = df['price']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cf58d6",
   "metadata": {},
   "source": [
    "## MODEL - REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75871d3a",
   "metadata": {},
   "source": [
    "### üîπ **Mean Squared Error (MSE)**\n",
    "\n",
    "* Yes ‚Äî the **smaller the MSE, the better** the model is fitting the data.\n",
    "* A **large MSE** means predictions are far from actual values.\n",
    "* But keep in mind: ‚Äúlarge‚Äù or ‚Äúsmall‚Äù is **relative to your target values‚Äô scale**.\n",
    "\n",
    "  * Example: if house prices are in **millions**, then an MSE in billions might still be okay.\n",
    "  * That‚Äôs why people often look at **RMSE** (square root of MSE), since it‚Äôs in the same units as the target.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **R¬≤ Score**\n",
    "\n",
    "* Correct: **higher is better**.\n",
    "* **R¬≤ = 1** ‚Üí perfect fit.\n",
    "* **R¬≤ = 0** ‚Üí model is no better than predicting the mean of the target.\n",
    "* **R¬≤ < 0** ‚Üí model is doing worse than just predicting the mean (bad performance).\n",
    "\n",
    "#### Small clarification:\n",
    "\n",
    "* R¬≤ doesn‚Äôt have to always be **positive**.\n",
    "* If it‚Äôs negative ‚Üí model is **underperforming** badly.\n",
    "* So:\n",
    "\n",
    "  * Good model ‚Üí R¬≤ close to 1.\n",
    "  * Okay model ‚Üí R¬≤ between 0 and 1.\n",
    "  * Bad model ‚Üí R¬≤ < 0.\n",
    "\n",
    "---\n",
    "\n",
    "#### **So yes, your takeaway is correct:**\n",
    "\n",
    "* **MSE should be as small as possible**.\n",
    "* **R¬≤ should be as close to 1 as possible** (positive and high).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2b5728b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "409db1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [139.55555556]\n",
      "Intercept: 34066.66666666677\n",
      "MSE: 1613995308.6419744\n",
      "RMSE: 40174.56046607075\n",
      "R¬≤ Score: -0.4381780428977273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "\n",
    "print(\"Coefficients:\", coefficients)\n",
    "print(\"Intercept:\", intercept)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R¬≤ Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "64e74dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1864812500.0\n",
      "RMSE: 43183.47484860384\n",
      "R¬≤ Score: -0.661672978391624\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth=5, min_samples_split=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R¬≤ Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a7d789c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2965239250.0\n",
      "RMSE: 54454.010412457224\n",
      "R¬≤ Score: -1.6422269993316996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R¬≤ Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f6c5631b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1992506008.2792974\n",
      "RMSE: 44637.49554219297\n",
      "R¬≤ Score: -0.7754564564752038\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = SVR(kernel=\"rbf\") # linear, poly, rbf\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R¬≤ Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2dcc678f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1019111111.1111101\n",
      "RMSE: 31923.51971683433\n",
      "R¬≤ Score: 0.09190366575084863\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R¬≤ Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5fd091da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 4662499997.2924385\n",
      "RMSE: 68282.50139891214\n",
      "R¬≤ Score: -3.154600131247439\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R¬≤ Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cc7d4f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 4662500000.0\n",
      "RMSE: 68282.50141873832\n",
      "R¬≤ Score: -3.1546001336600575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R¬≤ Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cda4b6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 5382369280.0\n",
      "RMSE: 73364.63235101775\n",
      "R¬≤ Score: -3.7960519790649414\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = XGBRegressor(n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R¬≤ Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e1fb87b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 4, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 251250.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "MSE: 1864812500.0\n",
      "RMSE: 43183.47484860384\n",
      "R¬≤ Score: -0.661672978391624\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = LGBMRegressor(n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R¬≤ Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "55d5a847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 42704.5146071\ttotal: 1.11ms\tremaining: 221ms\n",
      "1:\tlearn: 41368.4881991\ttotal: 2.74ms\tremaining: 272ms\n",
      "2:\tlearn: 40081.2272353\ttotal: 3.31ms\tremaining: 217ms\n",
      "3:\tlearn: 39079.1965395\ttotal: 3.88ms\tremaining: 190ms\n",
      "4:\tlearn: 38403.4386238\ttotal: 4.3ms\tremaining: 168ms\n",
      "5:\tlearn: 37819.1089931\ttotal: 5.12ms\tremaining: 166ms\n",
      "6:\tlearn: 36642.0646522\ttotal: 5.68ms\tremaining: 157ms\n",
      "7:\tlearn: 35726.0130223\ttotal: 6.12ms\tremaining: 147ms\n",
      "8:\tlearn: 34415.5655184\ttotal: 6.43ms\tremaining: 136ms\n",
      "9:\tlearn: 33364.7750630\ttotal: 6.77ms\tremaining: 129ms\n",
      "10:\tlearn: 32530.6556740\ttotal: 7.16ms\tremaining: 123ms\n",
      "11:\tlearn: 31351.1776580\ttotal: 7.49ms\tremaining: 117ms\n",
      "12:\tlearn: 30223.4403152\ttotal: 7.78ms\tremaining: 112ms\n",
      "13:\tlearn: 29145.5046997\ttotal: 8.06ms\tremaining: 107ms\n",
      "14:\tlearn: 28416.8670714\ttotal: 8.48ms\tremaining: 105ms\n",
      "15:\tlearn: 27838.6735718\ttotal: 8.8ms\tremaining: 101ms\n",
      "16:\tlearn: 27142.7067222\ttotal: 9.17ms\tremaining: 98.7ms\n",
      "17:\tlearn: 26464.1390440\ttotal: 9.46ms\tremaining: 95.7ms\n",
      "18:\tlearn: 25930.8796146\ttotal: 9.76ms\tremaining: 93ms\n",
      "19:\tlearn: 25001.4541380\ttotal: 9.99ms\tremaining: 89.9ms\n",
      "20:\tlearn: 24235.1080664\ttotal: 10.2ms\tremaining: 87.4ms\n",
      "21:\tlearn: 23629.2303557\ttotal: 10.6ms\tremaining: 85.4ms\n",
      "22:\tlearn: 22922.6062077\ttotal: 10.8ms\tremaining: 83.2ms\n",
      "23:\tlearn: 22243.1375606\ttotal: 11.1ms\tremaining: 81.2ms\n",
      "24:\tlearn: 21687.0591133\ttotal: 11.4ms\tremaining: 79.6ms\n",
      "25:\tlearn: 21144.8826274\ttotal: 11.7ms\tremaining: 78.1ms\n",
      "26:\tlearn: 20616.2605539\ttotal: 11.9ms\tremaining: 76.5ms\n",
      "27:\tlearn: 19895.1925198\ttotal: 12.2ms\tremaining: 74.9ms\n",
      "28:\tlearn: 19397.8126993\ttotal: 12.5ms\tremaining: 73.5ms\n",
      "29:\tlearn: 18726.5332390\ttotal: 12.7ms\tremaining: 71.7ms\n",
      "30:\tlearn: 18085.8335915\ttotal: 12.8ms\tremaining: 69.9ms\n",
      "31:\tlearn: 17474.5764709\ttotal: 13ms\tremaining: 68.2ms\n",
      "32:\tlearn: 16891.6670233\ttotal: 13.2ms\tremaining: 66.7ms\n",
      "33:\tlearn: 16336.0505515\ttotal: 13.3ms\tremaining: 65.1ms\n",
      "34:\tlearn: 15927.6492817\ttotal: 13.5ms\tremaining: 63.9ms\n",
      "35:\tlearn: 15411.5425465\ttotal: 13.7ms\tremaining: 62.5ms\n",
      "36:\tlearn: 14920.0987314\ttotal: 13.9ms\tremaining: 61.2ms\n",
      "37:\tlearn: 14484.2113873\ttotal: 14.2ms\tremaining: 60.3ms\n",
      "38:\tlearn: 14064.4003382\ttotal: 14.5ms\tremaining: 60ms\n",
      "39:\tlearn: 13712.7903245\ttotal: 14.8ms\tremaining: 59.3ms\n",
      "40:\tlearn: 13369.9705613\ttotal: 15.2ms\tremaining: 59.1ms\n",
      "41:\tlearn: 13035.7212923\ttotal: 15.8ms\tremaining: 59.4ms\n",
      "42:\tlearn: 12709.8282551\ttotal: 16.4ms\tremaining: 60ms\n",
      "43:\tlearn: 12392.0825440\ttotal: 16.8ms\tremaining: 59.6ms\n",
      "44:\tlearn: 12082.2804758\ttotal: 17.2ms\tremaining: 59.1ms\n",
      "45:\tlearn: 11780.2234594\ttotal: 17.4ms\tremaining: 58.2ms\n",
      "46:\tlearn: 11485.7178685\ttotal: 17.6ms\tremaining: 57.2ms\n",
      "47:\tlearn: 11198.5749175\ttotal: 17.8ms\tremaining: 56.3ms\n",
      "48:\tlearn: 10918.6105404\ttotal: 18ms\tremaining: 55.3ms\n",
      "49:\tlearn: 10645.6452729\ttotal: 18.1ms\tremaining: 54.4ms\n",
      "50:\tlearn: 10379.5041371\ttotal: 18.3ms\tremaining: 53.5ms\n",
      "51:\tlearn: 10120.0165298\ttotal: 18.5ms\tremaining: 52.6ms\n",
      "52:\tlearn: 9867.0161128\ttotal: 18.7ms\tremaining: 51.7ms\n",
      "53:\tlearn: 9620.3407063\ttotal: 18.9ms\tremaining: 51ms\n",
      "54:\tlearn: 9379.8321850\ttotal: 19ms\tremaining: 50.2ms\n",
      "55:\tlearn: 9145.3363769\ttotal: 19.2ms\tremaining: 49.4ms\n",
      "56:\tlearn: 8916.7029641\ttotal: 19.4ms\tremaining: 48.7ms\n",
      "57:\tlearn: 8693.7853867\ttotal: 19.6ms\tremaining: 47.9ms\n",
      "58:\tlearn: 8476.4407487\ttotal: 19.7ms\tremaining: 47.2ms\n",
      "59:\tlearn: 8264.5297269\ttotal: 19.9ms\tremaining: 46.5ms\n",
      "60:\tlearn: 8057.9164806\ttotal: 20.1ms\tremaining: 45.8ms\n",
      "61:\tlearn: 7856.4685656\ttotal: 20.3ms\tremaining: 45.2ms\n",
      "62:\tlearn: 7660.0568485\ttotal: 20.5ms\tremaining: 44.5ms\n",
      "63:\tlearn: 7468.5554245\ttotal: 20.7ms\tremaining: 43.9ms\n",
      "64:\tlearn: 7281.8415361\ttotal: 20.9ms\tremaining: 43.3ms\n",
      "65:\tlearn: 7099.7954950\ttotal: 21ms\tremaining: 42.7ms\n",
      "66:\tlearn: 6922.3006049\ttotal: 21.2ms\tremaining: 42.1ms\n",
      "67:\tlearn: 6749.2430872\ttotal: 21.4ms\tremaining: 41.6ms\n",
      "68:\tlearn: 6580.5120075\ttotal: 21.6ms\tremaining: 41ms\n",
      "69:\tlearn: 6415.9992049\ttotal: 21.8ms\tremaining: 40.4ms\n",
      "70:\tlearn: 6255.5992224\ttotal: 22ms\tremaining: 39.9ms\n",
      "71:\tlearn: 6099.2092395\ttotal: 22.2ms\tremaining: 39.4ms\n",
      "72:\tlearn: 5946.7290062\ttotal: 22.4ms\tremaining: 38.9ms\n",
      "73:\tlearn: 5798.0607789\ttotal: 22.6ms\tremaining: 38.4ms\n",
      "74:\tlearn: 5653.1092572\ttotal: 22.7ms\tremaining: 37.9ms\n",
      "75:\tlearn: 5511.7815237\ttotal: 22.9ms\tremaining: 37.4ms\n",
      "76:\tlearn: 5373.9869836\ttotal: 23.1ms\tremaining: 36.9ms\n",
      "77:\tlearn: 5239.6373070\ttotal: 23.3ms\tremaining: 36.4ms\n",
      "78:\tlearn: 5108.6463723\ttotal: 23.4ms\tremaining: 35.9ms\n",
      "79:\tlearn: 4980.9302111\ttotal: 23.6ms\tremaining: 35.4ms\n",
      "80:\tlearn: 4856.4069540\ttotal: 23.8ms\tremaining: 35ms\n",
      "81:\tlearn: 4734.9967783\ttotal: 24ms\tremaining: 34.5ms\n",
      "82:\tlearn: 4616.6218571\ttotal: 24.2ms\tremaining: 34.1ms\n",
      "83:\tlearn: 4501.2063090\ttotal: 24.4ms\tremaining: 33.7ms\n",
      "84:\tlearn: 4388.6761496\ttotal: 24.6ms\tremaining: 33.3ms\n",
      "85:\tlearn: 4278.9592442\ttotal: 24.9ms\tremaining: 33ms\n",
      "86:\tlearn: 4171.9852615\ttotal: 25.1ms\tremaining: 32.6ms\n",
      "87:\tlearn: 4067.6856284\ttotal: 25.3ms\tremaining: 32.1ms\n",
      "88:\tlearn: 3965.9934862\ttotal: 25.5ms\tremaining: 31.8ms\n",
      "89:\tlearn: 3866.8436475\ttotal: 26.2ms\tremaining: 32ms\n",
      "90:\tlearn: 3770.1725549\ttotal: 26.6ms\tremaining: 31.9ms\n",
      "91:\tlearn: 3675.9182396\ttotal: 27ms\tremaining: 31.6ms\n",
      "92:\tlearn: 3584.0202823\ttotal: 27.2ms\tremaining: 31.3ms\n",
      "93:\tlearn: 3494.4197739\ttotal: 27.4ms\tremaining: 30.9ms\n",
      "94:\tlearn: 3407.0592782\ttotal: 27.6ms\tremaining: 30.5ms\n",
      "95:\tlearn: 3321.8827950\ttotal: 27.7ms\tremaining: 30.1ms\n",
      "96:\tlearn: 3238.8357239\ttotal: 27.9ms\tremaining: 29.6ms\n",
      "97:\tlearn: 3157.8648296\ttotal: 28.1ms\tremaining: 29.3ms\n",
      "98:\tlearn: 3078.9182077\ttotal: 28.3ms\tremaining: 28.9ms\n",
      "99:\tlearn: 3001.9452513\ttotal: 28.5ms\tremaining: 28.5ms\n",
      "100:\tlearn: 2926.8966189\ttotal: 28.7ms\tremaining: 28.1ms\n",
      "101:\tlearn: 2853.7242024\ttotal: 28.9ms\tremaining: 27.8ms\n",
      "102:\tlearn: 2782.3810963\ttotal: 29.1ms\tremaining: 27.4ms\n",
      "103:\tlearn: 2712.8215678\ttotal: 29.3ms\tremaining: 27ms\n",
      "104:\tlearn: 2645.0010276\ttotal: 29.4ms\tremaining: 26.6ms\n",
      "105:\tlearn: 2578.8760009\ttotal: 29.6ms\tremaining: 26.3ms\n",
      "106:\tlearn: 2514.4040999\ttotal: 29.8ms\tremaining: 25.9ms\n",
      "107:\tlearn: 2451.5439965\ttotal: 30ms\tremaining: 25.5ms\n",
      "108:\tlearn: 2390.2553957\ttotal: 30.2ms\tremaining: 25.2ms\n",
      "109:\tlearn: 2330.4990099\ttotal: 30.4ms\tremaining: 24.8ms\n",
      "110:\tlearn: 2272.2365338\ttotal: 30.5ms\tremaining: 24.5ms\n",
      "111:\tlearn: 2215.4306196\ttotal: 30.7ms\tremaining: 24.1ms\n",
      "112:\tlearn: 2160.0448533\ttotal: 30.9ms\tremaining: 23.8ms\n",
      "113:\tlearn: 2106.0437311\ttotal: 31.1ms\tremaining: 23.5ms\n",
      "114:\tlearn: 2053.3926371\ttotal: 31.3ms\tremaining: 23.1ms\n",
      "115:\tlearn: 2002.0578204\ttotal: 31.5ms\tremaining: 22.8ms\n",
      "116:\tlearn: 1952.0063741\ttotal: 31.7ms\tremaining: 22.5ms\n",
      "117:\tlearn: 1903.2062140\ttotal: 31.8ms\tremaining: 22.1ms\n",
      "118:\tlearn: 1855.6260580\ttotal: 32ms\tremaining: 21.8ms\n",
      "119:\tlearn: 1809.2354058\ttotal: 32.2ms\tremaining: 21.5ms\n",
      "120:\tlearn: 1764.0045200\ttotal: 32.4ms\tremaining: 21.1ms\n",
      "121:\tlearn: 1719.9044064\ttotal: 32.6ms\tremaining: 20.8ms\n",
      "122:\tlearn: 1676.9067956\ttotal: 32.7ms\tremaining: 20.5ms\n",
      "123:\tlearn: 1634.9841251\ttotal: 32.9ms\tremaining: 20.2ms\n",
      "124:\tlearn: 1594.1095213\ttotal: 33.1ms\tremaining: 19.8ms\n",
      "125:\tlearn: 1554.2567827\ttotal: 33.3ms\tremaining: 19.5ms\n",
      "126:\tlearn: 1515.4003625\ttotal: 33.5ms\tremaining: 19.2ms\n",
      "127:\tlearn: 1477.5153529\ttotal: 33.6ms\tremaining: 18.9ms\n",
      "128:\tlearn: 1440.5774685\ttotal: 33.8ms\tremaining: 18.6ms\n",
      "129:\tlearn: 1404.5630313\ttotal: 34ms\tremaining: 18.3ms\n",
      "130:\tlearn: 1369.4489550\ttotal: 34.2ms\tremaining: 18ms\n",
      "131:\tlearn: 1335.2127306\ttotal: 34.4ms\tremaining: 17.7ms\n",
      "132:\tlearn: 1301.8324118\ttotal: 34.5ms\tremaining: 17.4ms\n",
      "133:\tlearn: 1269.2866011\ttotal: 34.7ms\tremaining: 17.1ms\n",
      "134:\tlearn: 1237.5544356\ttotal: 35ms\tremaining: 16.8ms\n",
      "135:\tlearn: 1206.6155742\ttotal: 35.1ms\tremaining: 16.5ms\n",
      "136:\tlearn: 1176.4501844\ttotal: 35.3ms\tremaining: 16.2ms\n",
      "137:\tlearn: 1147.0389294\ttotal: 35.5ms\tremaining: 15.9ms\n",
      "138:\tlearn: 1118.3629557\ttotal: 35.6ms\tremaining: 15.6ms\n",
      "139:\tlearn: 1090.4038814\ttotal: 35.8ms\tremaining: 15.4ms\n",
      "140:\tlearn: 1063.1437839\ttotal: 36ms\tremaining: 15.1ms\n",
      "141:\tlearn: 1036.5651890\ttotal: 36.2ms\tremaining: 14.8ms\n",
      "142:\tlearn: 1010.6510588\ttotal: 36.4ms\tremaining: 14.5ms\n",
      "143:\tlearn: 985.3847820\ttotal: 37.2ms\tremaining: 14.5ms\n",
      "144:\tlearn: 960.7501621\ttotal: 37.7ms\tremaining: 14.3ms\n",
      "145:\tlearn: 936.7314077\ttotal: 38.1ms\tremaining: 14.1ms\n",
      "146:\tlearn: 913.3131221\ttotal: 38.3ms\tremaining: 13.8ms\n",
      "147:\tlearn: 890.4802937\ttotal: 38.5ms\tremaining: 13.5ms\n",
      "148:\tlearn: 868.2182861\ttotal: 38.7ms\tremaining: 13.2ms\n",
      "149:\tlearn: 846.5128286\ttotal: 38.8ms\tremaining: 12.9ms\n",
      "150:\tlearn: 825.3500076\ttotal: 39ms\tremaining: 12.7ms\n",
      "151:\tlearn: 804.7162571\ttotal: 39.2ms\tremaining: 12.4ms\n",
      "152:\tlearn: 784.5983503\ttotal: 39.4ms\tremaining: 12.1ms\n",
      "153:\tlearn: 764.9833913\ttotal: 39.6ms\tremaining: 11.8ms\n",
      "154:\tlearn: 745.8588062\ttotal: 39.7ms\tremaining: 11.5ms\n",
      "155:\tlearn: 727.2123358\ttotal: 39.9ms\tremaining: 11.3ms\n",
      "156:\tlearn: 709.0320271\ttotal: 40.2ms\tremaining: 11ms\n",
      "157:\tlearn: 691.3062262\ttotal: 40.4ms\tremaining: 10.7ms\n",
      "158:\tlearn: 674.0235703\ttotal: 40.5ms\tremaining: 10.5ms\n",
      "159:\tlearn: 657.1729808\ttotal: 40.7ms\tremaining: 10.2ms\n",
      "160:\tlearn: 640.7436560\ttotal: 40.9ms\tremaining: 9.91ms\n",
      "161:\tlearn: 624.7250644\ttotal: 41.1ms\tremaining: 9.64ms\n",
      "162:\tlearn: 609.1069375\ttotal: 41.3ms\tremaining: 9.37ms\n",
      "163:\tlearn: 593.8792638\ttotal: 41.4ms\tremaining: 9.1ms\n",
      "164:\tlearn: 579.0322820\ttotal: 41.6ms\tremaining: 8.83ms\n",
      "165:\tlearn: 564.5564748\ttotal: 41.8ms\tremaining: 8.56ms\n",
      "166:\tlearn: 550.4425627\ttotal: 42ms\tremaining: 8.3ms\n",
      "167:\tlearn: 536.6814984\ttotal: 42.2ms\tremaining: 8.03ms\n",
      "168:\tlearn: 523.2644608\ttotal: 42.3ms\tremaining: 7.76ms\n",
      "169:\tlearn: 510.1828490\ttotal: 42.5ms\tremaining: 7.5ms\n",
      "170:\tlearn: 497.4282776\ttotal: 42.7ms\tremaining: 7.24ms\n",
      "171:\tlearn: 484.9925705\ttotal: 42.9ms\tremaining: 6.98ms\n",
      "172:\tlearn: 472.8677561\ttotal: 43.1ms\tremaining: 6.72ms\n",
      "173:\tlearn: 461.0460620\ttotal: 43.3ms\tremaining: 6.46ms\n",
      "174:\tlearn: 449.5199103\ttotal: 43.4ms\tremaining: 6.2ms\n",
      "175:\tlearn: 438.2819123\ttotal: 43.6ms\tremaining: 5.95ms\n",
      "176:\tlearn: 427.3248644\ttotal: 43.8ms\tremaining: 5.69ms\n",
      "177:\tlearn: 416.6417426\ttotal: 44ms\tremaining: 5.43ms\n",
      "178:\tlearn: 406.2256989\ttotal: 44.2ms\tremaining: 5.18ms\n",
      "179:\tlearn: 396.0700562\ttotal: 44.4ms\tremaining: 4.93ms\n",
      "180:\tlearn: 386.1683047\ttotal: 44.5ms\tremaining: 4.67ms\n",
      "181:\tlearn: 376.5140969\ttotal: 44.7ms\tremaining: 4.42ms\n",
      "182:\tlearn: 367.1012444\ttotal: 44.9ms\tremaining: 4.17ms\n",
      "183:\tlearn: 357.9237131\ttotal: 45.1ms\tremaining: 3.92ms\n",
      "184:\tlearn: 348.9756202\ttotal: 45.2ms\tremaining: 3.67ms\n",
      "185:\tlearn: 340.2512295\ttotal: 45.4ms\tremaining: 3.42ms\n",
      "186:\tlearn: 331.7449487\ttotal: 45.6ms\tremaining: 3.17ms\n",
      "187:\tlearn: 323.4513248\ttotal: 45.8ms\tremaining: 2.92ms\n",
      "188:\tlearn: 315.3650416\ttotal: 46ms\tremaining: 2.67ms\n",
      "189:\tlearn: 307.4809154\ttotal: 46.2ms\tremaining: 2.43ms\n",
      "190:\tlearn: 299.7938924\ttotal: 46.5ms\tremaining: 2.19ms\n",
      "191:\tlearn: 292.2990450\ttotal: 46.8ms\tremaining: 1.95ms\n",
      "192:\tlearn: 284.9915688\ttotal: 47ms\tremaining: 1.7ms\n",
      "193:\tlearn: 277.8667794\ttotal: 47.3ms\tremaining: 1.46ms\n",
      "194:\tlearn: 270.9201099\ttotal: 47.5ms\tremaining: 1.22ms\n",
      "195:\tlearn: 264.1471070\ttotal: 47.7ms\tremaining: 972us\n",
      "196:\tlearn: 257.5434292\ttotal: 47.8ms\tremaining: 728us\n",
      "197:\tlearn: 251.1048434\ttotal: 48.1ms\tremaining: 486us\n",
      "198:\tlearn: 244.8272222\ttotal: 48.3ms\tremaining: 242us\n",
      "199:\tlearn: 238.7065416\ttotal: 48.8ms\tremaining: 0us\n",
      "MSE: 4648751796.44011\n",
      "RMSE: 68181.75559810785\n",
      "R¬≤ Score: -3.1423495624327114\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = CatBoostRegressor(n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R¬≤ Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31fe5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e3bc266",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "df1611de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"age\": [22, 25, 47, 52, 46, 56, 55, 60],\n",
    "    \"salary\": [25000, 32000, 47000, 60000, 42000, 52000, 58000, 72000],\n",
    "    \"purchased\": [0, 0, 1, 1, 1, 1, 1, 1]  \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "X = df[[\"age\", \"salary\"]]\n",
    "y = df[\"purchased\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59272d4d",
   "metadata": {},
   "source": [
    "#### Simple Regression Problem Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fced15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Hyperparameters: {'regressor__subsample': 1.0, 'regressor__reg_lambda': 2, 'regressor__reg_alpha': 0.1, 'regressor__n_estimators': 150, 'regressor__max_depth': 6, 'regressor__learning_rate': 0.1, 'regressor__gamma': 0, 'regressor__colsample_bytree': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV R¬≤: nan\n",
      "CV RMSE: 480.3297329885621\n",
      "CV MAE: 480.329736328125\n",
      "Test MSE: 1957034.125\n",
      "Test RMSE: 1398.9403579138034\n",
      "Test MAE: 1203.402099609375\n",
      "Test R¬≤: -0.043442368507385254\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 1. Import libraries\n",
    "# -------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_validate\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Load dataset (example)\n",
    "# -------------------------------\n",
    "data = {\n",
    "    \"age\": [22, 25, 47, 52, 46, 56, 55, 60],\n",
    "    \"salary\": [25000, 32000, 47000, 60000, 42000, 52000, 58000, 72000],\n",
    "    \"expenses\": [1000, 1200, 3000, 3500, 2800, 4000, 3800, 5000]  # target variable\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "X = df[[\"age\", \"salary\"]]\n",
    "y = df[\"expenses\"]\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Train-Test Split\n",
    "# -------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Build ML pipeline\n",
    "# -------------------------------\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', RobustScaler()),                           # Robust scaling\n",
    "    ('feature_selection', SelectKBest(f_regression, k='all')),  # Feature selection\n",
    "    ('regressor', XGBRegressor(random_state=42))          # XGBoost Regressor\n",
    "])\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Hyperparameter space for tuning\n",
    "# -------------------------------\n",
    "param_dist = {\n",
    "    'regressor__n_estimators': [50, 100, 150, 200],\n",
    "    'regressor__max_depth': [3, 4, 5, 6],\n",
    "    'regressor__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'regressor__subsample': [0.6, 0.8, 1.0],\n",
    "    'regressor__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'regressor__gamma': [0, 0.1, 0.2],\n",
    "    'regressor__reg_alpha': [0, 0.01, 0.1],\n",
    "    'regressor__reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 6. RandomizedSearchCV for tuning\n",
    "# -------------------------------\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,                  # Number of random combinations\n",
    "    scoring='neg_mean_squared_error',  # Optimize for MSE\n",
    "    cv=5,                       # 5-fold CV\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Fit the model\n",
    "# -------------------------------\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Cross-validation with multiple metrics\n",
    "# -------------------------------\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    best_model, X_train, y_train, cv=5,\n",
    "    scoring=('r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'),\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(\"CV R¬≤:\", np.mean(cv_results['test_r2']))\n",
    "print(\"CV RMSE:\", np.mean(np.sqrt(-cv_results['test_neg_mean_squared_error'])))\n",
    "print(\"CV MAE:\", np.mean(-cv_results['test_neg_mean_absolute_error']))\n",
    "\n",
    "# -------------------------------\n",
    "# 9. Evaluate model on test set\n",
    "# -------------------------------\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test MAE:\", mae)\n",
    "print(\"Test R¬≤:\", r2)\n",
    "\n",
    "# -------------------------------\n",
    "# 10. Feature importance visualization\n",
    "# -------------------------------\n",
    "regressor = best_model.named_steps['regressor']\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(X.columns, regressor.feature_importances_)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.ylabel(\"Importance Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c01088",
   "metadata": {},
   "source": [
    "## MODEL - CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a098495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "655859c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e4323440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a0e1ef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a244bd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      " [[0 1]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = SVC(kernel=\"rbf\", probability=True, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      " [[0 1]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4f8abab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      " [[0 1]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "94f29587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1f85464c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b50c7158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      " [[0 1]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:36:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"n_estimator\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = XGBClassifier(n_estimator=200, learning_rate=0.1, max_depth=3, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aca0b9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: n_estimator\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Unknown parameter: n_estimator\n",
      "[LightGBM] [Info] Number of positive: 5, number of negative: 1\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 6, number of used features: 0\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.833333 -> initscore=1.609438\n",
      "[LightGBM] [Info] Start training from score 1.609438\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Unknown parameter: n_estimator\n",
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      " [[0 1]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = LGBMClassifier(n_estimator=200, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "065aff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = CatBoostClassifier(iterations=200, learning_rate=0.1, depth=3, verbose=0, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7cedb9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=200, max_depth=None, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e56c98e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=200, max_depth=None, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "599e0be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "model = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('dt', tree_clf), ('knn', knn_clf)],\n",
    "    voting='hard'   # 'hard' = majority vote, 'soft' = average predicted probabilities\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a6a9d54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42, class_weight=\"balanced\").fit(X_train, y_train)\n",
    "svc = SVC(probability=True, random_state=42, class_weight=\"balanced\").fit(X_train, y_train)\n",
    "\n",
    "final_estimator = LogisticRegression(class_weight=\"balanced\")\n",
    "\n",
    "model = StackingClassifier(\n",
    "    estimators=[('dt', dt), ('svc', svc)],\n",
    "    final_estimator=final_estimator,\n",
    "    cv=\"prefit\"\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "base_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "\n",
    "model = BaggingClassifier(\n",
    "    estimator=base_model,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc70bbaf",
   "metadata": {},
   "source": [
    "#### Simple Classification Problem Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c40dda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:811: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "30 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1641, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0], got [1]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:46:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:811: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:46:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:106: RuntimeWarning: invalid value encountered in divide\n",
      "  msb = ssbn / float(dfbn)\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:46:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "1 fits failed out of a total of 3.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1641, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0], got [1]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'classifier__subsample': 0.8, 'classifier__reg_lambda': 2, 'classifier__reg_alpha': 0, 'classifier__n_estimators': 100, 'classifier__max_depth': 6, 'classifier__learning_rate': 0.01, 'classifier__gamma': 0.1, 'classifier__colsample_bytree': 0.8}\n",
      "5-Fold CV Accuracy on Training Set: nan\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Confusion Matrix:\n",
      " [[0 1]\n",
      " [0 2]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.33      0.50      0.40         3\n",
      "weighted avg       0.44      0.67      0.53         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 1. Import libraries\n",
    "# -------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Load dataset\n",
    "# -------------------------------\n",
    "data = {\n",
    "    \"age\": [22, 25, 47, 52, 46, 56, 55, 60],\n",
    "    \"salary\": [25000, 32000, 47000, 60000, 42000, 52000, 58000, 72000],\n",
    "    \"purchased\": [0, 0, 1, 1, 1, 1, 1, 1]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "X = df[[\"age\", \"salary\"]]\n",
    "y = df[\"purchased\"]\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Train-Test Split with stratification\n",
    "# -------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Build ML pipeline\n",
    "# -------------------------------\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),             # Step 1: Scale features\n",
    "    ('feature_selection', SelectKBest(f_classif, k='all')),  # Step 2: Feature selection\n",
    "    ('classifier', XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        random_state=42\n",
    "    ))                                        # Step 3: Classifier\n",
    "])\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Hyperparameter space for tuning\n",
    "# -------------------------------\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': [50, 100, 150, 200],\n",
    "    'classifier__max_depth': [3, 4, 5, 6],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'classifier__subsample': [0.6, 0.8, 1.0],\n",
    "    'classifier__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'classifier__gamma': [0, 0.1, 0.2],\n",
    "    'classifier__reg_alpha': [0, 0.01, 0.1],\n",
    "    'classifier__reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 6. RandomizedSearchCV for tuning\n",
    "# -------------------------------\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,                  # Number of random combinations to try\n",
    "    scoring='accuracy',         # Metric to optimize\n",
    "    cv=3,                       # 3-fold cross-validation\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Fit the model\n",
    "# -------------------------------\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Evaluate model\n",
    "# -------------------------------\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Cross-validation score\n",
    "cv_scores = cross_val_score(best_model, X_train, y_train, cv=3, scoring='accuracy')\n",
    "print(\"5-Fold CV Accuracy on Training Set:\", cv_scores.mean())\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Accuracy and classification report\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# -------------------------------\n",
    "# 9. Feature importance visualization\n",
    "# -------------------------------\n",
    "# Extract the classifier from pipeline\n",
    "clf = best_model.named_steps['classifier']\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(X.columns, clf.feature_importances_)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.ylabel(\"Importance Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2035bfc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
