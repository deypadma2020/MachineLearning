{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc502191",
   "metadata": {},
   "source": [
    "## MACHINE LEARNING MODELS: -\n",
    "\n",
    "#### üîπ Classical Models\n",
    "\n",
    "- Logistic Regression\n",
    "\n",
    "- K-Nearest Neighbors (KNN)\n",
    "\n",
    "- Support Vector Classifier (SVC)\n",
    "\n",
    "- Decision Tree\n",
    "\n",
    "- Naive Bayes\n",
    "\n",
    "#### üîπ Ensemble Models\n",
    "\n",
    "- Random Forest\n",
    "\n",
    "- Extra Trees\n",
    "\n",
    "- Bagging Classifier\n",
    "\n",
    "- AdaBoost\n",
    "\n",
    "- Gradient Boosting\n",
    "\n",
    "- XGBoost\n",
    "\n",
    "- LightGBM\n",
    "\n",
    "- CatBoost\n",
    "\n",
    "#### üîπ Meta-Ensemble Models\n",
    "\n",
    "- Voting Classifier\n",
    "\n",
    "- Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be55d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f0971ac",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e173f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    \"area\": [1400, 1600, 1700, 1875, 1100, 1550],\n",
    "    \"price\": [245000, 312000, 279000, 308000, 199000, 219000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "X = df[[\"area\"]]\n",
    "y = df['price']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cf58d6",
   "metadata": {},
   "source": [
    "## MODEL - REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75871d3a",
   "metadata": {},
   "source": [
    "### üîπ **Mean Squared Error (MSE)**\n",
    "\n",
    "* Yes ‚Äî the **smaller the MSE, the better** the model is fitting the data.\n",
    "* A **large MSE** means predictions are far from actual values.\n",
    "* But keep in mind: ‚Äúlarge‚Äù or ‚Äúsmall‚Äù is **relative to your target values‚Äô scale**.\n",
    "\n",
    "  * Example: if house prices are in **millions**, then an MSE in billions might still be okay.\n",
    "  * That‚Äôs why people often look at **RMSE** (square root of MSE), since it‚Äôs in the same units as the target.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **R¬≤ Score**\n",
    "\n",
    "* Correct: **higher is better**.\n",
    "* **R¬≤ = 1** ‚Üí perfect fit.\n",
    "* **R¬≤ = 0** ‚Üí model is no better than predicting the mean of the target.\n",
    "* **R¬≤ < 0** ‚Üí model is doing worse than just predicting the mean (bad performance).\n",
    "\n",
    "#### Small clarification:\n",
    "\n",
    "* R¬≤ doesn‚Äôt have to always be **positive**.\n",
    "* If it‚Äôs negative ‚Üí model is **underperforming** badly.\n",
    "* So:\n",
    "\n",
    "  * Good model ‚Üí R¬≤ close to 1.\n",
    "  * Okay model ‚Üí R¬≤ between 0 and 1.\n",
    "  * Bad model ‚Üí R¬≤ < 0.\n",
    "\n",
    "---\n",
    "\n",
    "#### **So yes, your takeaway is correct:**\n",
    "\n",
    "* **MSE should be as small as possible**.\n",
    "* **R¬≤ should be as close to 1 as possible** (positive and high).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2b5728b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "409db1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [139.55555556]\n",
      "Intercept: 34066.66666666677\n",
      "MSE: 1613995308.6419744\n",
      "RMSE: 40174.56046607075\n",
      "R¬≤ Score: -0.4381780428977273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "\n",
    "print(\"Coefficients:\", coefficients)\n",
    "print(\"Intercept:\", intercept)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R¬≤ Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "64e74dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1864812500.0\n",
      "RMSE: 43183.47484860384\n",
      "R¬≤ Score: -0.661672978391624\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth=5, min_samples_split=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R¬≤ Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a7d789c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2965239250.0\n",
      "RMSE: 54454.010412457224\n",
      "R¬≤ Score: -1.6422269993316996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R¬≤ Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f6c5631b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1992506008.2792974\n",
      "RMSE: 44637.49554219297\n",
      "R¬≤ Score: -0.7754564564752038\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = SVR(kernel=\"rbf\") # linear, poly, rbf\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R¬≤ Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2dcc678f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1019111111.1111101\n",
      "RMSE: 31923.51971683433\n",
      "R¬≤ Score: 0.09190366575084863\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R¬≤ Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5fd091da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 4662499997.2924385\n",
      "RMSE: 68282.50139891214\n",
      "R¬≤ Score: -3.154600131247439\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R¬≤ Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cc7d4f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 4662500000.0\n",
      "RMSE: 68282.50141873832\n",
      "R¬≤ Score: -3.1546001336600575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R¬≤ Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cda4b6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 5382369280.0\n",
      "RMSE: 73364.63235101775\n",
      "R¬≤ Score: -3.7960519790649414\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = XGBRegressor(n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R¬≤ Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e1fb87b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 4, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 251250.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "MSE: 1864812500.0\n",
      "RMSE: 43183.47484860384\n",
      "R¬≤ Score: -0.661672978391624\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = LGBMRegressor(n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R¬≤ Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "55d5a847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 42704.5146071\ttotal: 1.11ms\tremaining: 221ms\n",
      "1:\tlearn: 41368.4881991\ttotal: 2.74ms\tremaining: 272ms\n",
      "2:\tlearn: 40081.2272353\ttotal: 3.31ms\tremaining: 217ms\n",
      "3:\tlearn: 39079.1965395\ttotal: 3.88ms\tremaining: 190ms\n",
      "4:\tlearn: 38403.4386238\ttotal: 4.3ms\tremaining: 168ms\n",
      "5:\tlearn: 37819.1089931\ttotal: 5.12ms\tremaining: 166ms\n",
      "6:\tlearn: 36642.0646522\ttotal: 5.68ms\tremaining: 157ms\n",
      "7:\tlearn: 35726.0130223\ttotal: 6.12ms\tremaining: 147ms\n",
      "8:\tlearn: 34415.5655184\ttotal: 6.43ms\tremaining: 136ms\n",
      "9:\tlearn: 33364.7750630\ttotal: 6.77ms\tremaining: 129ms\n",
      "10:\tlearn: 32530.6556740\ttotal: 7.16ms\tremaining: 123ms\n",
      "11:\tlearn: 31351.1776580\ttotal: 7.49ms\tremaining: 117ms\n",
      "12:\tlearn: 30223.4403152\ttotal: 7.78ms\tremaining: 112ms\n",
      "13:\tlearn: 29145.5046997\ttotal: 8.06ms\tremaining: 107ms\n",
      "14:\tlearn: 28416.8670714\ttotal: 8.48ms\tremaining: 105ms\n",
      "15:\tlearn: 27838.6735718\ttotal: 8.8ms\tremaining: 101ms\n",
      "16:\tlearn: 27142.7067222\ttotal: 9.17ms\tremaining: 98.7ms\n",
      "17:\tlearn: 26464.1390440\ttotal: 9.46ms\tremaining: 95.7ms\n",
      "18:\tlearn: 25930.8796146\ttotal: 9.76ms\tremaining: 93ms\n",
      "19:\tlearn: 25001.4541380\ttotal: 9.99ms\tremaining: 89.9ms\n",
      "20:\tlearn: 24235.1080664\ttotal: 10.2ms\tremaining: 87.4ms\n",
      "21:\tlearn: 23629.2303557\ttotal: 10.6ms\tremaining: 85.4ms\n",
      "22:\tlearn: 22922.6062077\ttotal: 10.8ms\tremaining: 83.2ms\n",
      "23:\tlearn: 22243.1375606\ttotal: 11.1ms\tremaining: 81.2ms\n",
      "24:\tlearn: 21687.0591133\ttotal: 11.4ms\tremaining: 79.6ms\n",
      "25:\tlearn: 21144.8826274\ttotal: 11.7ms\tremaining: 78.1ms\n",
      "26:\tlearn: 20616.2605539\ttotal: 11.9ms\tremaining: 76.5ms\n",
      "27:\tlearn: 19895.1925198\ttotal: 12.2ms\tremaining: 74.9ms\n",
      "28:\tlearn: 19397.8126993\ttotal: 12.5ms\tremaining: 73.5ms\n",
      "29:\tlearn: 18726.5332390\ttotal: 12.7ms\tremaining: 71.7ms\n",
      "30:\tlearn: 18085.8335915\ttotal: 12.8ms\tremaining: 69.9ms\n",
      "31:\tlearn: 17474.5764709\ttotal: 13ms\tremaining: 68.2ms\n",
      "32:\tlearn: 16891.6670233\ttotal: 13.2ms\tremaining: 66.7ms\n",
      "33:\tlearn: 16336.0505515\ttotal: 13.3ms\tremaining: 65.1ms\n",
      "34:\tlearn: 15927.6492817\ttotal: 13.5ms\tremaining: 63.9ms\n",
      "35:\tlearn: 15411.5425465\ttotal: 13.7ms\tremaining: 62.5ms\n",
      "36:\tlearn: 14920.0987314\ttotal: 13.9ms\tremaining: 61.2ms\n",
      "37:\tlearn: 14484.2113873\ttotal: 14.2ms\tremaining: 60.3ms\n",
      "38:\tlearn: 14064.4003382\ttotal: 14.5ms\tremaining: 60ms\n",
      "39:\tlearn: 13712.7903245\ttotal: 14.8ms\tremaining: 59.3ms\n",
      "40:\tlearn: 13369.9705613\ttotal: 15.2ms\tremaining: 59.1ms\n",
      "41:\tlearn: 13035.7212923\ttotal: 15.8ms\tremaining: 59.4ms\n",
      "42:\tlearn: 12709.8282551\ttotal: 16.4ms\tremaining: 60ms\n",
      "43:\tlearn: 12392.0825440\ttotal: 16.8ms\tremaining: 59.6ms\n",
      "44:\tlearn: 12082.2804758\ttotal: 17.2ms\tremaining: 59.1ms\n",
      "45:\tlearn: 11780.2234594\ttotal: 17.4ms\tremaining: 58.2ms\n",
      "46:\tlearn: 11485.7178685\ttotal: 17.6ms\tremaining: 57.2ms\n",
      "47:\tlearn: 11198.5749175\ttotal: 17.8ms\tremaining: 56.3ms\n",
      "48:\tlearn: 10918.6105404\ttotal: 18ms\tremaining: 55.3ms\n",
      "49:\tlearn: 10645.6452729\ttotal: 18.1ms\tremaining: 54.4ms\n",
      "50:\tlearn: 10379.5041371\ttotal: 18.3ms\tremaining: 53.5ms\n",
      "51:\tlearn: 10120.0165298\ttotal: 18.5ms\tremaining: 52.6ms\n",
      "52:\tlearn: 9867.0161128\ttotal: 18.7ms\tremaining: 51.7ms\n",
      "53:\tlearn: 9620.3407063\ttotal: 18.9ms\tremaining: 51ms\n",
      "54:\tlearn: 9379.8321850\ttotal: 19ms\tremaining: 50.2ms\n",
      "55:\tlearn: 9145.3363769\ttotal: 19.2ms\tremaining: 49.4ms\n",
      "56:\tlearn: 8916.7029641\ttotal: 19.4ms\tremaining: 48.7ms\n",
      "57:\tlearn: 8693.7853867\ttotal: 19.6ms\tremaining: 47.9ms\n",
      "58:\tlearn: 8476.4407487\ttotal: 19.7ms\tremaining: 47.2ms\n",
      "59:\tlearn: 8264.5297269\ttotal: 19.9ms\tremaining: 46.5ms\n",
      "60:\tlearn: 8057.9164806\ttotal: 20.1ms\tremaining: 45.8ms\n",
      "61:\tlearn: 7856.4685656\ttotal: 20.3ms\tremaining: 45.2ms\n",
      "62:\tlearn: 7660.0568485\ttotal: 20.5ms\tremaining: 44.5ms\n",
      "63:\tlearn: 7468.5554245\ttotal: 20.7ms\tremaining: 43.9ms\n",
      "64:\tlearn: 7281.8415361\ttotal: 20.9ms\tremaining: 43.3ms\n",
      "65:\tlearn: 7099.7954950\ttotal: 21ms\tremaining: 42.7ms\n",
      "66:\tlearn: 6922.3006049\ttotal: 21.2ms\tremaining: 42.1ms\n",
      "67:\tlearn: 6749.2430872\ttotal: 21.4ms\tremaining: 41.6ms\n",
      "68:\tlearn: 6580.5120075\ttotal: 21.6ms\tremaining: 41ms\n",
      "69:\tlearn: 6415.9992049\ttotal: 21.8ms\tremaining: 40.4ms\n",
      "70:\tlearn: 6255.5992224\ttotal: 22ms\tremaining: 39.9ms\n",
      "71:\tlearn: 6099.2092395\ttotal: 22.2ms\tremaining: 39.4ms\n",
      "72:\tlearn: 5946.7290062\ttotal: 22.4ms\tremaining: 38.9ms\n",
      "73:\tlearn: 5798.0607789\ttotal: 22.6ms\tremaining: 38.4ms\n",
      "74:\tlearn: 5653.1092572\ttotal: 22.7ms\tremaining: 37.9ms\n",
      "75:\tlearn: 5511.7815237\ttotal: 22.9ms\tremaining: 37.4ms\n",
      "76:\tlearn: 5373.9869836\ttotal: 23.1ms\tremaining: 36.9ms\n",
      "77:\tlearn: 5239.6373070\ttotal: 23.3ms\tremaining: 36.4ms\n",
      "78:\tlearn: 5108.6463723\ttotal: 23.4ms\tremaining: 35.9ms\n",
      "79:\tlearn: 4980.9302111\ttotal: 23.6ms\tremaining: 35.4ms\n",
      "80:\tlearn: 4856.4069540\ttotal: 23.8ms\tremaining: 35ms\n",
      "81:\tlearn: 4734.9967783\ttotal: 24ms\tremaining: 34.5ms\n",
      "82:\tlearn: 4616.6218571\ttotal: 24.2ms\tremaining: 34.1ms\n",
      "83:\tlearn: 4501.2063090\ttotal: 24.4ms\tremaining: 33.7ms\n",
      "84:\tlearn: 4388.6761496\ttotal: 24.6ms\tremaining: 33.3ms\n",
      "85:\tlearn: 4278.9592442\ttotal: 24.9ms\tremaining: 33ms\n",
      "86:\tlearn: 4171.9852615\ttotal: 25.1ms\tremaining: 32.6ms\n",
      "87:\tlearn: 4067.6856284\ttotal: 25.3ms\tremaining: 32.1ms\n",
      "88:\tlearn: 3965.9934862\ttotal: 25.5ms\tremaining: 31.8ms\n",
      "89:\tlearn: 3866.8436475\ttotal: 26.2ms\tremaining: 32ms\n",
      "90:\tlearn: 3770.1725549\ttotal: 26.6ms\tremaining: 31.9ms\n",
      "91:\tlearn: 3675.9182396\ttotal: 27ms\tremaining: 31.6ms\n",
      "92:\tlearn: 3584.0202823\ttotal: 27.2ms\tremaining: 31.3ms\n",
      "93:\tlearn: 3494.4197739\ttotal: 27.4ms\tremaining: 30.9ms\n",
      "94:\tlearn: 3407.0592782\ttotal: 27.6ms\tremaining: 30.5ms\n",
      "95:\tlearn: 3321.8827950\ttotal: 27.7ms\tremaining: 30.1ms\n",
      "96:\tlearn: 3238.8357239\ttotal: 27.9ms\tremaining: 29.6ms\n",
      "97:\tlearn: 3157.8648296\ttotal: 28.1ms\tremaining: 29.3ms\n",
      "98:\tlearn: 3078.9182077\ttotal: 28.3ms\tremaining: 28.9ms\n",
      "99:\tlearn: 3001.9452513\ttotal: 28.5ms\tremaining: 28.5ms\n",
      "100:\tlearn: 2926.8966189\ttotal: 28.7ms\tremaining: 28.1ms\n",
      "101:\tlearn: 2853.7242024\ttotal: 28.9ms\tremaining: 27.8ms\n",
      "102:\tlearn: 2782.3810963\ttotal: 29.1ms\tremaining: 27.4ms\n",
      "103:\tlearn: 2712.8215678\ttotal: 29.3ms\tremaining: 27ms\n",
      "104:\tlearn: 2645.0010276\ttotal: 29.4ms\tremaining: 26.6ms\n",
      "105:\tlearn: 2578.8760009\ttotal: 29.6ms\tremaining: 26.3ms\n",
      "106:\tlearn: 2514.4040999\ttotal: 29.8ms\tremaining: 25.9ms\n",
      "107:\tlearn: 2451.5439965\ttotal: 30ms\tremaining: 25.5ms\n",
      "108:\tlearn: 2390.2553957\ttotal: 30.2ms\tremaining: 25.2ms\n",
      "109:\tlearn: 2330.4990099\ttotal: 30.4ms\tremaining: 24.8ms\n",
      "110:\tlearn: 2272.2365338\ttotal: 30.5ms\tremaining: 24.5ms\n",
      "111:\tlearn: 2215.4306196\ttotal: 30.7ms\tremaining: 24.1ms\n",
      "112:\tlearn: 2160.0448533\ttotal: 30.9ms\tremaining: 23.8ms\n",
      "113:\tlearn: 2106.0437311\ttotal: 31.1ms\tremaining: 23.5ms\n",
      "114:\tlearn: 2053.3926371\ttotal: 31.3ms\tremaining: 23.1ms\n",
      "115:\tlearn: 2002.0578204\ttotal: 31.5ms\tremaining: 22.8ms\n",
      "116:\tlearn: 1952.0063741\ttotal: 31.7ms\tremaining: 22.5ms\n",
      "117:\tlearn: 1903.2062140\ttotal: 31.8ms\tremaining: 22.1ms\n",
      "118:\tlearn: 1855.6260580\ttotal: 32ms\tremaining: 21.8ms\n",
      "119:\tlearn: 1809.2354058\ttotal: 32.2ms\tremaining: 21.5ms\n",
      "120:\tlearn: 1764.0045200\ttotal: 32.4ms\tremaining: 21.1ms\n",
      "121:\tlearn: 1719.9044064\ttotal: 32.6ms\tremaining: 20.8ms\n",
      "122:\tlearn: 1676.9067956\ttotal: 32.7ms\tremaining: 20.5ms\n",
      "123:\tlearn: 1634.9841251\ttotal: 32.9ms\tremaining: 20.2ms\n",
      "124:\tlearn: 1594.1095213\ttotal: 33.1ms\tremaining: 19.8ms\n",
      "125:\tlearn: 1554.2567827\ttotal: 33.3ms\tremaining: 19.5ms\n",
      "126:\tlearn: 1515.4003625\ttotal: 33.5ms\tremaining: 19.2ms\n",
      "127:\tlearn: 1477.5153529\ttotal: 33.6ms\tremaining: 18.9ms\n",
      "128:\tlearn: 1440.5774685\ttotal: 33.8ms\tremaining: 18.6ms\n",
      "129:\tlearn: 1404.5630313\ttotal: 34ms\tremaining: 18.3ms\n",
      "130:\tlearn: 1369.4489550\ttotal: 34.2ms\tremaining: 18ms\n",
      "131:\tlearn: 1335.2127306\ttotal: 34.4ms\tremaining: 17.7ms\n",
      "132:\tlearn: 1301.8324118\ttotal: 34.5ms\tremaining: 17.4ms\n",
      "133:\tlearn: 1269.2866011\ttotal: 34.7ms\tremaining: 17.1ms\n",
      "134:\tlearn: 1237.5544356\ttotal: 35ms\tremaining: 16.8ms\n",
      "135:\tlearn: 1206.6155742\ttotal: 35.1ms\tremaining: 16.5ms\n",
      "136:\tlearn: 1176.4501844\ttotal: 35.3ms\tremaining: 16.2ms\n",
      "137:\tlearn: 1147.0389294\ttotal: 35.5ms\tremaining: 15.9ms\n",
      "138:\tlearn: 1118.3629557\ttotal: 35.6ms\tremaining: 15.6ms\n",
      "139:\tlearn: 1090.4038814\ttotal: 35.8ms\tremaining: 15.4ms\n",
      "140:\tlearn: 1063.1437839\ttotal: 36ms\tremaining: 15.1ms\n",
      "141:\tlearn: 1036.5651890\ttotal: 36.2ms\tremaining: 14.8ms\n",
      "142:\tlearn: 1010.6510588\ttotal: 36.4ms\tremaining: 14.5ms\n",
      "143:\tlearn: 985.3847820\ttotal: 37.2ms\tremaining: 14.5ms\n",
      "144:\tlearn: 960.7501621\ttotal: 37.7ms\tremaining: 14.3ms\n",
      "145:\tlearn: 936.7314077\ttotal: 38.1ms\tremaining: 14.1ms\n",
      "146:\tlearn: 913.3131221\ttotal: 38.3ms\tremaining: 13.8ms\n",
      "147:\tlearn: 890.4802937\ttotal: 38.5ms\tremaining: 13.5ms\n",
      "148:\tlearn: 868.2182861\ttotal: 38.7ms\tremaining: 13.2ms\n",
      "149:\tlearn: 846.5128286\ttotal: 38.8ms\tremaining: 12.9ms\n",
      "150:\tlearn: 825.3500076\ttotal: 39ms\tremaining: 12.7ms\n",
      "151:\tlearn: 804.7162571\ttotal: 39.2ms\tremaining: 12.4ms\n",
      "152:\tlearn: 784.5983503\ttotal: 39.4ms\tremaining: 12.1ms\n",
      "153:\tlearn: 764.9833913\ttotal: 39.6ms\tremaining: 11.8ms\n",
      "154:\tlearn: 745.8588062\ttotal: 39.7ms\tremaining: 11.5ms\n",
      "155:\tlearn: 727.2123358\ttotal: 39.9ms\tremaining: 11.3ms\n",
      "156:\tlearn: 709.0320271\ttotal: 40.2ms\tremaining: 11ms\n",
      "157:\tlearn: 691.3062262\ttotal: 40.4ms\tremaining: 10.7ms\n",
      "158:\tlearn: 674.0235703\ttotal: 40.5ms\tremaining: 10.5ms\n",
      "159:\tlearn: 657.1729808\ttotal: 40.7ms\tremaining: 10.2ms\n",
      "160:\tlearn: 640.7436560\ttotal: 40.9ms\tremaining: 9.91ms\n",
      "161:\tlearn: 624.7250644\ttotal: 41.1ms\tremaining: 9.64ms\n",
      "162:\tlearn: 609.1069375\ttotal: 41.3ms\tremaining: 9.37ms\n",
      "163:\tlearn: 593.8792638\ttotal: 41.4ms\tremaining: 9.1ms\n",
      "164:\tlearn: 579.0322820\ttotal: 41.6ms\tremaining: 8.83ms\n",
      "165:\tlearn: 564.5564748\ttotal: 41.8ms\tremaining: 8.56ms\n",
      "166:\tlearn: 550.4425627\ttotal: 42ms\tremaining: 8.3ms\n",
      "167:\tlearn: 536.6814984\ttotal: 42.2ms\tremaining: 8.03ms\n",
      "168:\tlearn: 523.2644608\ttotal: 42.3ms\tremaining: 7.76ms\n",
      "169:\tlearn: 510.1828490\ttotal: 42.5ms\tremaining: 7.5ms\n",
      "170:\tlearn: 497.4282776\ttotal: 42.7ms\tremaining: 7.24ms\n",
      "171:\tlearn: 484.9925705\ttotal: 42.9ms\tremaining: 6.98ms\n",
      "172:\tlearn: 472.8677561\ttotal: 43.1ms\tremaining: 6.72ms\n",
      "173:\tlearn: 461.0460620\ttotal: 43.3ms\tremaining: 6.46ms\n",
      "174:\tlearn: 449.5199103\ttotal: 43.4ms\tremaining: 6.2ms\n",
      "175:\tlearn: 438.2819123\ttotal: 43.6ms\tremaining: 5.95ms\n",
      "176:\tlearn: 427.3248644\ttotal: 43.8ms\tremaining: 5.69ms\n",
      "177:\tlearn: 416.6417426\ttotal: 44ms\tremaining: 5.43ms\n",
      "178:\tlearn: 406.2256989\ttotal: 44.2ms\tremaining: 5.18ms\n",
      "179:\tlearn: 396.0700562\ttotal: 44.4ms\tremaining: 4.93ms\n",
      "180:\tlearn: 386.1683047\ttotal: 44.5ms\tremaining: 4.67ms\n",
      "181:\tlearn: 376.5140969\ttotal: 44.7ms\tremaining: 4.42ms\n",
      "182:\tlearn: 367.1012444\ttotal: 44.9ms\tremaining: 4.17ms\n",
      "183:\tlearn: 357.9237131\ttotal: 45.1ms\tremaining: 3.92ms\n",
      "184:\tlearn: 348.9756202\ttotal: 45.2ms\tremaining: 3.67ms\n",
      "185:\tlearn: 340.2512295\ttotal: 45.4ms\tremaining: 3.42ms\n",
      "186:\tlearn: 331.7449487\ttotal: 45.6ms\tremaining: 3.17ms\n",
      "187:\tlearn: 323.4513248\ttotal: 45.8ms\tremaining: 2.92ms\n",
      "188:\tlearn: 315.3650416\ttotal: 46ms\tremaining: 2.67ms\n",
      "189:\tlearn: 307.4809154\ttotal: 46.2ms\tremaining: 2.43ms\n",
      "190:\tlearn: 299.7938924\ttotal: 46.5ms\tremaining: 2.19ms\n",
      "191:\tlearn: 292.2990450\ttotal: 46.8ms\tremaining: 1.95ms\n",
      "192:\tlearn: 284.9915688\ttotal: 47ms\tremaining: 1.7ms\n",
      "193:\tlearn: 277.8667794\ttotal: 47.3ms\tremaining: 1.46ms\n",
      "194:\tlearn: 270.9201099\ttotal: 47.5ms\tremaining: 1.22ms\n",
      "195:\tlearn: 264.1471070\ttotal: 47.7ms\tremaining: 972us\n",
      "196:\tlearn: 257.5434292\ttotal: 47.8ms\tremaining: 728us\n",
      "197:\tlearn: 251.1048434\ttotal: 48.1ms\tremaining: 486us\n",
      "198:\tlearn: 244.8272222\ttotal: 48.3ms\tremaining: 242us\n",
      "199:\tlearn: 238.7065416\ttotal: 48.8ms\tremaining: 0us\n",
      "MSE: 4648751796.44011\n",
      "RMSE: 68181.75559810785\n",
      "R¬≤ Score: -3.1423495624327114\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = CatBoostRegressor(n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R¬≤ Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31fe5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e3bc266",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "df1611de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"age\": [22, 25, 47, 52, 46, 56, 55, 60],\n",
    "    \"salary\": [25000, 32000, 47000, 60000, 42000, 52000, 58000, 72000],\n",
    "    \"purchased\": [0, 0, 1, 1, 1, 1, 1, 1]  \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "X = df[[\"age\", \"salary\"]]\n",
    "y = df[\"purchased\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c01088",
   "metadata": {},
   "source": [
    "## MODEL - CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a098495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "655859c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e4323440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a0e1ef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a244bd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      " [[0 1]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = SVC(kernel=\"rbf\", probability=True, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      " [[0 1]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4f8abab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      " [[0 1]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "94f29587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1f85464c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b50c7158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      " [[0 1]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:36:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"n_estimator\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = XGBClassifier(n_estimator=200, learning_rate=0.1, max_depth=3, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aca0b9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: n_estimator\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Unknown parameter: n_estimator\n",
      "[LightGBM] [Info] Number of positive: 5, number of negative: 1\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 6, number of used features: 0\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.833333 -> initscore=1.609438\n",
      "[LightGBM] [Info] Start training from score 1.609438\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Unknown parameter: n_estimator\n",
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      " [[0 1]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "f:\\PANTA\\due\\MachineLearning\\ml_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = LGBMClassifier(n_estimator=200, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "065aff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = CatBoostClassifier(iterations=200, learning_rate=0.1, depth=3, verbose=0, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7cedb9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=200, max_depth=None, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e56c98e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=200, max_depth=None, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "599e0be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "model = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('dt', tree_clf), ('knn', knn_clf)],\n",
    "    voting='hard'   # 'hard' = majority vote, 'soft' = average predicted probabilities\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a6a9d54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42, class_weight=\"balanced\").fit(X_train, y_train)\n",
    "svc = SVC(probability=True, random_state=42, class_weight=\"balanced\").fit(X_train, y_train)\n",
    "\n",
    "final_estimator = LogisticRegression(class_weight=\"balanced\")\n",
    "\n",
    "model = StackingClassifier(\n",
    "    estimators=[('dt', dt), ('svc', svc)],\n",
    "    final_estimator=final_estimator,\n",
    "    cv=\"prefit\"\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "base_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "\n",
    "model = BaggingClassifier(\n",
    "    estimator=base_model,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c40dda0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
